{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hixBQ3rw-qEd",
        "outputId": "b0057090-f360-43a2-da8e-2498dfc5be73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Hariprasad\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Hariprasad\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "import mlflow.sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9GW2Tfs4-wni",
        "outputId": "9b5b2927-a5b5-4b02-c221-d7828c6a7edd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv').drop(columns=['tweet_id'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vVhMBkqK_cB9",
        "outputId": "f12f0dda-11a5-4609-ece3-ac6e6ba4f711"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@JohnLloydTaylor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>love</td>\n",
              "      <td>Happy Mothers Day  All my love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>love</td>\n",
              "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>happiness</td>\n",
              "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>love</td>\n",
              "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment                                            content\n",
              "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2         sadness                Funeral ceremony...gloomy friday...\n",
              "3      enthusiasm               wants to hang out with friends SOON!\n",
              "4         neutral  @dannycastillo We want to trade with someone w...\n",
              "...           ...                                                ...\n",
              "39995     neutral                                   @JohnLloydTaylor\n",
              "39996        love                     Happy Mothers Day  All my love\n",
              "39997        love  Happy Mother's Day to all the mommies out ther...\n",
              "39998   happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
              "39999        love  @mopedronin bullet train from tokyo    the gf ...\n",
              "\n",
              "[40000 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1RUbsP6v-y-_"
      },
      "outputs": [],
      "source": [
        "# data preprocessing\n",
        "\n",
        "# Define text preprocessing functions\n",
        "def lemmatization(text):\n",
        "    \"\"\"Lemmatize the text.\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = text.split()\n",
        "    text = [lemmatizer.lemmatize(word) for word in text]\n",
        "    return \" \".join(text)\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    \"\"\"Remove stop words from the text.\"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    text = [word for word in str(text).split() if word not in stop_words]\n",
        "    return \" \".join(text)\n",
        "\n",
        "def removing_numbers(text):\n",
        "    \"\"\"Remove numbers from the text.\"\"\"\n",
        "    text = ''.join([char for char in text if not char.isdigit()])\n",
        "    return text\n",
        "\n",
        "def lower_case(text):\n",
        "    \"\"\"Convert text to lower case.\"\"\"\n",
        "    text = text.split()\n",
        "    text = [word.lower() for word in text]\n",
        "    return \" \".join(text)\n",
        "\n",
        "def removing_punctuations(text):\n",
        "    \"\"\"Remove punctuations from the text.\"\"\"\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = text.replace('؛', \"\")\n",
        "    text = re.sub('\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def removing_urls(text):\n",
        "    \"\"\"Remove URLs from the text.\"\"\"\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "def normalize_text(df):\n",
        "    \"\"\"Normalize the text data.\"\"\"\n",
        "    try:\n",
        "        df['content'] = df['content'].apply(lower_case)\n",
        "        df['content'] = df['content'].apply(remove_stop_words)\n",
        "        df['content'] = df['content'].apply(removing_numbers)\n",
        "        df['content'] = df['content'].apply(removing_punctuations)\n",
        "        df['content'] = df['content'].apply(removing_urls)\n",
        "        df['content'] = df['content'].apply(lemmatization)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f'Error during text normalization: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9cmoHiW_Iz7",
        "outputId": "ef289d26-2e9d-4d08-94da-fa216bb215b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>want hang friend soon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>dannycastillo want trade someone houston ticke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  tiffanylue know listenin bad habit earlier sta...\n",
              "1     sadness            layin n bed headache ughhhh waitin call\n",
              "2     sadness                     funeral ceremony gloomy friday\n",
              "3  enthusiasm                              want hang friend soon\n",
              "4     neutral  dannycastillo want trade someone houston ticke..."
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=normalize_text(df)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gM5cO-HL_MBO"
      },
      "outputs": [],
      "source": [
        "x = df['sentiment'].isin(['happiness','sadness'])\n",
        "df = df[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "lCacX0cWActD",
        "outputId": "e1bbb009-cdc1-466f-81a9-71cd3ed445d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hariprasad\\AppData\\Local\\Temp\\ipykernel_6632\\1089524538.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['sentiment'] = df['sentiment'].replace({'sadness':0, 'happiness':1})\n",
            "C:\\Users\\Hariprasad\\AppData\\Local\\Temp\\ipykernel_6632\\1089524538.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['sentiment'] = df['sentiment'].replace({'sadness':0, 'happiness':1})\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>sleep im not thinking old friend want he s mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>charviray charlene love miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>kelcouch i m sorry least friday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            content\n",
              "1          0            layin n bed headache ughhhh waitin call\n",
              "2          0                     funeral ceremony gloomy friday\n",
              "6          0  sleep im not thinking old friend want he s mar...\n",
              "8          0                       charviray charlene love miss\n",
              "9          0                    kelcouch i m sorry least friday"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'sadness':0, 'happiness':1})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NCfu7X22Ajsm"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['content'])\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O54SE3L3AmmM"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "3ef421b0a9a54f27b6aa5ef04d9c072f",
            "2d3b22e24b674bacb4c9ced9f49c3a1f"
          ]
        },
        "id": "6MysGfYQAqHs",
        "outputId": "07b9fcb9-ddde-4162-a8e9-0474d84b9c47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as kalehariprasad\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as kalehariprasad\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"kalehariprasad/emotion-detection\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"kalehariprasad/emotion-detection\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository kalehariprasad/emotion-detection initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository kalehariprasad/emotion-detection initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/d9af4f2a70ae485aa71f099a0461949d', creation_time=1727584621867, experiment_id='1', last_update_time=1727584621867, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import dagshub\n",
        "\n",
        "mlflow.set_tracking_uri('https://dagshub.com/kalehariprasad/emotion-detection.mlflow')\n",
        "dagshub.init(repo_owner='kalehariprasad', repo_name='emotion-detection', mlflow=True)\n",
        "\n",
        "mlflow.set_experiment(\"Logistic Regression Baseline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5fm2MnVBRqN",
        "outputId": "2b3fc509-ccf9-4974-fdc6-af650494014d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/09/29 12:03:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7759036144578313\n",
            "Precision: 0.7685546875\n",
            "Recall: 0.7753694581280788\n",
            "F1 Score: 0.7719470328592447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/09/29 12:03:23 INFO mlflow.tracking._tracking_service.client: 🏃 View run peaceful-jay-868 at: https://dagshub.com/kalehariprasad/emotion-detection.mlflow/#/experiments/1/runs/f7a6271ee4ad42d8bb409cb13c51fee1.\n",
            "2024/09/29 12:03:23 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/kalehariprasad/emotion-detection.mlflow/#/experiments/1.\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run():\n",
        "\n",
        "    # Log preprocessing parameters\n",
        "    mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
        "    mlflow.log_param(\"num_features\", 1000)\n",
        "    mlflow.log_param(\"test_size\", 0.2)\n",
        "\n",
        "    # Model building and training\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Log model parameters\n",
        "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
        "\n",
        "    # Model evaluation\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log evaluation metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Log model\n",
        "    mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "    # Save and log the notebook\n",
        "    import os\n",
        "    notebook_path = \"exp1_baseline_model.ipynb\"\n",
        "    os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
        "    mlflow.log_artifact(notebook_path)\n",
        "\n",
        "    # Print the results for verification\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W86ow5UsJznZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d3b22e24b674bacb4c9ced9f49c3a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef421b0a9a54f27b6aa5ef04d9c072f": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2d3b22e24b674bacb4c9ced9f49c3a1f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠼</span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32m⠼\u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
